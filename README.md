# Rakesh Kandula

**(326)-467-5867** • **[kandula.15@wright.edu](mailto:kandula.15@wright.edu)** • **[LinkedIn](https://www.linkedin.com/in/rakesh-kandula-41678314a/)**
<img src="https://media.licdn.com/dms/image/D4E03AQFaDx7voiKy_Q/profile-displayphoto-shrink_400_400/0/1711592385753?e=1722470400&v=beta&t=RXrz3aMYTnLDgkSjbCCGMPWxPDivyMDt45frJq8U8Do" alt="Rakesh Kandula" style="float: right; border-radius: 50%; width: 150px; height: 150px; margin-right: 20px;">
---

## SUMMARY
An experienced Machine Learning Engineer proficient in developing and deploying models across varied domains such as knowledge graphs and natural language processing. Beginner level expertise in large language models and Retrieval Augmented Generation.

---

## EDUCATION

**M.S. Computer Science**  
Wright State University, Dayton, OH  
**Expected:** May 2024  
**CGPA:** 4.00

Completed Coursework: Advanced Computer Networks, Algorithm Design and Analysis, Distributed Computing and HPC Parallel Programming  
Enrolled Coursework: Advanced Topics in Semantic Web  
Relevant Coursework: Introduction to Knowledge Engineering, Cloud Computing and Computer Vision Pattern Recognition  
Thesis Coursework: LLM Techniques to Query Knowledge Graphs through Natural Language Statements*

**B.Tech. Computer Science Engineering**  
Lovely Professional University, Punjab, India  
**Completed:** May 2020  
**CGPA:** 8.08

---

## TECHNICAL SKILLS

- **Programming Languages:** Python, C/C++, Java
- **Web Services:** RESTful APIs, Django Web Framework, FastAPI,
- **Frameworks:** PyTorch, Tensorflow, SpringBoot
- **Natural Language Processing:** Spacy
- **Databases:** PostgreSQL, SPARQL
- **Version Control Tools:** Git

---

## PROFESSIONAL EXPERIENCE

### Wright State University, Dayton, USA
**Knowledge Graphs Researcher – Knowledge Graphs,LLMs**  
**Duration:** June 2023 - Present

- Working as a research assistant in building the digital twin of Ohio known as Ohio-KWG, part of KnowWhereGraph's largest geo-spatial KG.
  - Modeling and developing Cybersecurity Hardware Knowledge Graph to detect the trustworthiness of hardware used in confidential areas.
  - Creating the Ohio-KWG and finetuning the KG data on an LLM to help provide information through natural language queries.
  - This project has future potential to represent Ohio data as a digital twin, making information easily accessible.

### Hughes Systique Corporation, Gurugram, India
### Project: HughesNet
**September 2020 - July 2022**  
**Gurugram, Haryana, India**  

**Project Description:**  
This project involved setting up broadband connections at the enterprise level and providing security features by issuing certificates using PKI infrastructure.

#### Situation
The project aimed to set up broadband connections at the enterprise level and provide security features through PKI infrastructure.

#### Task
My responsibilities included automating the configuration of network devices, understanding networking concepts, and setting up the PKI infrastructure.

#### Action
1. Worked as a backend developer to automate the configuration of devices like routers and AA’s.
2. Dealt with various networking concepts and implementing the functinality to SSH into routers to execute commands and validate credentials.
3. Collaborated with a 3-member team to set up PKI infrastructure, gaining knowledge about Certificate Authorities, PKI Vendors, and authentication processes.
4. Developed the project using the Django Framework, designing and implementing a microservice architecture from scratch and creating a web interface.

#### Result
The successful implementation of the project ensured secure broadband connections at the enterprise level, with a robust PKI infrastructure that enhanced security features and provided reliable authentication.

### Machine Learning Intern
**January 2020 - August 2020**  
**Gurugram, Haryana, India**   

As a Machine Learning Intern at Hughes Systique Corporation, I was part of a team dedicated to developing and deploying advanced machine learning models. 

My primary responsibilities included fine-tuning models and improving system accuracy using machine learning and deep learning frameworks such as PyTorch and TensorFlow.

1. Led multiple projects where I utilized PyTorch and TensorFlow for various tasks including natural language processing, sentiment analysis, and predictive analytics.
2. Applied hands-on experience to specialize in these frameworks, focusing on the refinement and optimization of models.
3. Engaged in fine-tuning models to enhance their performance and achieve higher accuracy.
4. Conducted extensive research on different ML and DL techniques to continuously improve my technical skills and the overall project outcomes.

#### Result
These efforts led to significant improvements in model performance and accuracy. The optimizations and refinements I implemented contributed to the successful deployment of advanced machine learning models, enhancing the system's overall capabilities and reliability.


---

## ACADEMIC PROJECTS

### Travel Destinations Recommendation Knowledge Graph

- Collaborated with a team to develop a knowledge graph with travel data targeting UK cities, answering queries about location details, activities, cuisines, etc., helping users make decisions. The Knowledge Graph can also recommend information when implemented with machine learning models.

### Traffic Volume Prediction through Real-Time Streaming Data: A Distributed Machine Learning Approach

- Designed a distributed system to simulate real-time data using Kafka and consume the data using Spark to predict real-time traffic volume. Steps included data preprocessing, model training, testing, and validation. Trained with different models like Linear Regression, Random Forests, and LSTM. Received professor's appreciation as the best project of the class.

### Student Performance Prediction using different ML models and AWS deployment

- Part of a 7-day ML boot camp where I developed a project at an industry level by creating a data ingestion pipeline, data preprocessing pipeline, training, and prediction pipeline. After completion, the project was deployed on AWS, creating a CI/CD pipeline. This project helped me land the job as a GRA.
